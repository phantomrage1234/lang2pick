# SO-101 ROS2 â€” Open-Source General Purpose Manipulator  
### Natural Language â†’ Vision-Language-Action (VLA) â†’ MoveIt2 â†’ Robot Execution

---

## ğŸŒ Inspiration

Growing up in India, I often saw plastic bottles, cans, wrappers, and recyclables littering the streets. It always felt like a **solvable problem** â€” if only technology could lend a hand (literally).

This project was born from that simple idea:  
> **What if a robotic arm could autonomously identify and pick up recyclables â€” cleaning our environment, one object at a time?**

SO-101 ROS2 is a step toward that future: an **open-source, modular robotic manipulation platform** that combines **natural language understanding**, **vision-language-action models**, and **robust motion planning** to enable real-world pick-and-place tasks.

---

## ğŸš€ Overview

**SO-101 ROS2** is a fully open-source framework for building **general-purpose robotic manipulators** using the **SO-101 robotic arm**. It enables **natural language-driven pick-and-place** operations via a complete software stack:

> **Example Command:**  
> _â€œPick up all recyclables and place them in the blue recycling bin.â€_

The system bridges the full pipeline:  
**Language â†’ Perception â†’ Action Planning â†’ Hardware Execution**

### ğŸ¯ End Goal
Provide developers with a **plug-and-play platform** to:
- Fine-tune **Vision-Language-Action (VLA)** models
- Control **any ROS2-compatible robotic arm** via `ros2_control`
- Perform **robust pick-and-place** tasks in simulation and reality

---

## ğŸ§  System Architecture

```mermaid
%%{init: {'theme': 'neutral', 'themeVariables': {
  'primaryColor': '#ffffff',
  'edgeLabelBackground':'#ffffff',
  'fontSize': '14px'
}}}%%
graph TD
    A["ğŸ—£ï¸ Natural Language Command"]
    F["ğŸ“· RGB-D Camera (Perception)"]
    B{"Vision Language Action Model"}
    C["ğŸ¦¾ MoveIt 2 Motion Planner"]
    D["âš™ï¸ ros2_control interface"]
    E[" SO-101 Arm + Grippers"]

    A --> B
    F --> B
    B -->|"ğŸ¯ Target Object & Action Tokens"| C
    C -->|"ğŸ”§ Optimized Joint Trajectories"| D
    D --> E

    %% Styling (consistent look)
    style A fill:#e1f5fe,stroke:#333,stroke-width:1px
    style B fill:#ffccbc,stroke:#333,stroke-width:1px
    style C fill:#fff3e0,stroke:#333,stroke-width:1px
    style D fill:#e0f7fa,stroke:#333,stroke-width:1px
    style E fill:#c8e6c9,stroke:#333,stroke-width:1px
    style F fill:#fce4ec,stroke:#333,stroke-width:1px

```

## ğŸ“ Project Structure

| Directory | Description |
|------------|-------------|
| `ros2_ws/` | ROS2 workspace containing robot description, MoveIt2 configuration, controller setup, hardware interface nodes and simulation |
| `vla/` | Vision-Language(-Action) module â€” converts VLA outputs (object/action tokens) into ROS2 commands for MoveIt2 |
| `scripts/` | Training and fine-tuning pipeline for the Vision-Language model (using **PyTorch** and **LeRobot**) |
| `docs/` | Documentation, diagrams, and setup guides for developers and contributors |

---

## ğŸ§© Tech Stack

- **ROS2 Humble** â€” Core robotics framework  
- **MoveIt2** â€” Inverse kinematics and motion planning  
- **PyTorch + LeRobot** â€” Vision-Language training & fine-tuning  
- **Gazebo / MuJoCo Sim** â€” Physics simulation and visualization  

---

## ğŸ¤ Contributing

Contributions are welcome! Whether you want to help with ROS2 development, dataset collection, or model training â€” feel free to open an issue or a PR.  

> Letâ€™s build robots that make the world cleaner, one recyclable at a time â™»ï¸

---

## ğŸ“œ License

This project is open-source and licensed under the [Apache License](LICENSE).

---

## â­ Acknowledgements

This project builds on the shoulders of open-source giants â€”  
**MoveIt2**, **ROS2**, **PyTorch**, **LeRobot**, and the amazing open-source robotics community.

---